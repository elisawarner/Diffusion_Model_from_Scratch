{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model for Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Author:** Elisa Warner  \n",
    "**Email:** elisawa@umich.edu  \n",
    "**Date:** 04/12/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms\n",
    "import torchvision.models as models\n",
    "from unet_mha import *\n",
    "from config import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Utility_Diffusion():\n",
    "    \"\"\"\n",
    "    Saves and calculates parameters needed for the diffusion model\n",
    "    \n",
    "    Parameters:\n",
    "     - beta_start = the min range of the beta scheduler\n",
    "     - beta_end = the max range of the beta scheduler\n",
    "     - t = total time steps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, beta_start=BETA_START, beta_end=BETA_END, time=T):\n",
    "        self.beta = np.linspace(beta_start, beta_end, time)\n",
    "        self.alpha_t = 1 - self.beta\n",
    "        self.alpha_bar_t = np.cumprod(self.alpha_t)\n",
    "        self.T = time\n",
    "    \n",
    "    def Samplet(self, N):\n",
    "        \"\"\"\n",
    "        Samples a time step t from a uniform distribution\n",
    "        \"\"\"\n",
    "        return np.random.randint(0, self.T, size=N)\n",
    "    \n",
    "    def SampleNoise(self, N):\n",
    "        \"\"\"\n",
    "        Samples normally distributed noise at the same size as the image\n",
    "        \"\"\"\n",
    "        return np.random.normal(size = (N,3,SQ_SIZE,SQ_SIZE))\n",
    "    \n",
    "    # forward process\n",
    "    def GetXt(self, x0, t, noise):\n",
    "        \"\"\"\n",
    "        Performs the forward process for adding step-wise Gaussian noise to the image x0\n",
    "        \"\"\"\n",
    "        beta_t = self.beta[t]\n",
    "        alpha_t = self.alpha_t[t]\n",
    "        alpha_bar_t = self.alpha_bar_t[t]\n",
    "        return (np.sqrt(alpha_bar_t) * x0) + (np.sqrt(1 - alpha_bar_t) * noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transforms applied to images\n",
    "transforms = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Resize((SQ_SIZE,SQ_SIZE), antialias=True),\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset and dataloader\n",
    "dataset = torchvision.datasets.ImageFolder(cat_directory, transform=transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"This dataset contains %s examples\" % len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. View Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test that the Dataset works\n",
    "import matplotlib.pyplot as plt\n",
    "show_this_many = 3\n",
    "\n",
    "fig, ax = plt.subplots(1,show_this_many)\n",
    "for i in range(show_this_many):\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    \n",
    "    x = dataset[idx][0].T\n",
    "    x = (x.clamp(-1, 1) + 1) / 2\n",
    "    x = (x * 255).type(torch.uint8)\n",
    "    \n",
    "    ax[i].imshow(x)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. View Forward Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test noise generator\n",
    "steps = 10\n",
    "fig, ax = plt.subplots(1, steps, figsize=(20,40))\n",
    "stepsize = int(T / 10)\n",
    "sample_params = Utility_Diffusion() \n",
    "\n",
    "for i in range(steps):\n",
    "    \n",
    "    x = sample_params.GetXt(dataset[0][0], i*stepsize, sample_params.SampleNoise(1)[0,:,:,:]).T\n",
    "    x = (x.clamp(-1, 1) + 1) / 2\n",
    "    x = (x * 255).type(torch.uint8)\n",
    "    \n",
    "    ax[i].imshow(x)\n",
    "    ax[i].set_title(i*stepsize)\n",
    "    ax[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import model architecture\n",
    "model = UNet(3, 3)\n",
    "if device != \"cpu\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9) #, weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import saved parameters\n",
    "if MODEL_OUT in os.listdir(\".\"):\n",
    "    savedData = torch.load(MODEL_OUT)\n",
    "    startEpoch = savedData['epoch']\n",
    "    model.load_state_dict(savedData['model_state_dict'])\n",
    "    optimizer.load_state_dict(savedData['optimizer_state_dict'])\n",
    "    print(\"Model and optimizer loaded. Model left off at epoch\", startEpoch+1)\n",
    "else:\n",
    "    print(\"No model found. Creating new model.\")\n",
    "    startEpoch = 0\n",
    "    \n",
    "    with open(RESULTS_OUT, \"wb\") as f:\n",
    "        f.write((\"Begin training.\\n\").encode())\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view optimizer settings\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to change optimizer parameters after initialization (optional)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.001\n",
    "    g['momentum'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Begin training.\")\n",
    "\n",
    "model.train()\n",
    "diff_params = Utility_Diffusion()\n",
    "\n",
    "for epoch in range(startEpoch+1, EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for idx, (img_batch, _) in enumerate(train_dataloader):\n",
    "        print(\"Progress: {}%\".format(np.round(idx / len(train_dataloader) * 100),1), end = \"\\r\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # sample\n",
    "        n = img_batch.shape[0]\n",
    "        batch_t = diff_params.Samplet(n)\n",
    "        batch_noise = torch.Tensor(diff_params.SampleNoise(n))\n",
    "        \n",
    "        # generate noisy image\n",
    "        batch_noisy_img = torch.zeros((img_batch.shape))\n",
    "        \n",
    "        for i in range(n):\n",
    "            batch_noisy_img[i,:,:,:] = diff_params.GetXt(img_batch[i,:,:,:], batch_t[i], batch_noise[i,:,:,:])\n",
    "        \n",
    "        # prediction\n",
    "        pred = model(batch_noisy_img.to(device), torch.Tensor(batch_t).to(device))\n",
    "        \n",
    "        # loss\n",
    "        loss = torch.nn.MSELoss()(batch_noise.to(device), pred)\n",
    "        total_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "    ##### DOCUMENT #####\n",
    "    print(\"Epoch %s: %s\" % (epoch, total_loss / len(train_dataloader)))\n",
    "    \n",
    "    with open(RESULTS_OUT,\"ab\") as f:\n",
    "        f.write( (\"+-- Epoch %s: %s\\n\" % (epoch, (total_loss / len(train_dataloader)))).encode())\n",
    "    \n",
    "    #### save model #####\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, MODEL_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILITY Clear Cache : Run if CUDA memory is full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code if you run into a CUDA memory error to clear the cache. Sometimes the below code does not work and there is still a CUDA memory error. If this is the case, you may have to try the following:  \n",
    "    1. Refresh the notebook  \n",
    "    2. Exit Jupyter Notebook and restart. Alternatively. change the kernel to no kernel and then back to Python 3.    \n",
    "    3. Restart computer/virtual instance  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "a = torch.zeros(300000000, dtype=torch.int8)\n",
    "a = a.cuda()\n",
    "del a\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "from unet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reverse process\n",
    "def Sample():\n",
    "    sample_params = Utility_Diffusion()\n",
    "    xT = torch.Tensor(sample_params.SampleNoise(1)).to(device)\n",
    "    \n",
    "    xt = xT\n",
    "    for t in range(T-1, -1, -1):\n",
    "       \n",
    "        # assign z\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(xt)\n",
    "        else:\n",
    "            z = 0\n",
    "        \n",
    "        # assign alpha, alpha-bar\n",
    "        beta_t = torch.Tensor([sample_params.beta[t]])\n",
    "        alpha_t = torch.Tensor([sample_params.alpha_t[t]]).to(device)\n",
    "        alpha_bar_t = torch.Tensor([sample_params.alpha_bar_t[t]]).to(device)\n",
    "        sqrt_beta = torch.sqrt(beta_t).to(device)[0]\n",
    "        \n",
    "        # sample\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            xt = (1 / torch.sqrt(alpha_t)) \\\n",
    "                * ((xt - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * model(xt, torch.ones(1, dtype=torch.long)*t)) + (sqrt_beta * z))\n",
    "    \n",
    "    xt = xt.detach().cpu()\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savedData = torch.load(MODEL_OUT)\n",
    "epoch = savedData['epoch']\n",
    "\n",
    "# import model\n",
    "model = UNet(3, 3)\n",
    "\n",
    "if device != \"cpu\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(savedData['model_state_dict'])\n",
    "\n",
    "savedData = 0\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Sample()\n",
    "x = (x.clamp(-1, 1) + 1) / 2\n",
    "x = (x * 255).type(torch.uint8)\n",
    "\n",
    "plt.imshow(x[0].T)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"Generated_Image_Epoch_%s\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
